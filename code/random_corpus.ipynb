{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to create the corpus to be anotated\n",
    "\n",
    "This notebook randomly graps 300 legal decisions from the decisions folder and combines them into one JSON corpus.  \n",
    "This corpus will later be annotated from law students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from random import randint\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script goes throug the judgments in the folder and saves it with a 5% chance.  \n",
    "Only decisions that have grounds for decisions with over 8000 characters are concidered.  \n",
    "25 judgments are bached into one file, 8 files are saved. This leads to 200 judgments. The batch of 25 is neccessary due to the upload constrains of one MB in doccano.  \n",
    "In the end the names of all scraped decisions is saved into an extra file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'decisions/'\n",
    "corpus = ''\n",
    "i = 0\n",
    "count = 1\n",
    "scraped_decisions = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if randint(1, 101) < 6:\n",
    "        with open (path + file, encoding='utf8') as f:\n",
    "            data = json.load(f)\n",
    "            if len(data['text']) > 8000:\n",
    "                corpus += '{\"text\": \"' + data['text'] + '\"}'\n",
    "                i += 1\n",
    "                scraped_decisions.append(data['title'])\n",
    "    if i == 25 and count < 9:\n",
    "        with open('corpus' + str(count) + '.json', 'w', encoding='utf-8') as file:\n",
    "            json.dump(corpus, file, ensure_ascii=False)\n",
    "            corpus = ''\n",
    "            count += 1\n",
    "            i = 0\n",
    "            \n",
    "with open ('scraped_descisions.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(str(item) for item in scraped_decisions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
